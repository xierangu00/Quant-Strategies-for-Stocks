{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5VtFEfZzoVf"
      },
      "source": [
        "**Lecture 5 : Return Prediction with Random Forest **"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ETFMCJHMaq6h"
      },
      "outputs": [],
      "source": [
        "# Connecting the Python Code with the google drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Description**\n",
        "\n",
        "Input: /content/drive/MyDrive/MAF data/Features_seven_signals.csv.zip\n",
        "Created by: Lec5_Create Standardized Features.ipynb\n",
        "\n",
        " **Satandardized Features**\n",
        "\n",
        "* marketcap: market cap\n",
        "\n",
        "* investment: 12-month increase in total assets\n",
        "\n",
        "* accruals: ib - oancf\n",
        "\n",
        "* b2m: ceq/marketcap\n",
        "\n",
        "* ret_2_12: momentum (stock returns from month t-12 to t-2\n",
        "\n",
        "* CashFlow2AT: oancf/Assets (AT)\n",
        "*new_issue: Stocks issued over the previous 12 months\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gSzh0x0gI83j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6UrtAekr6vaE"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import platform\n",
        "import random\n",
        "from math import sqrt, floor, ceil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "from multiprocessing import Process\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import plot_tree\n",
        "\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRUG8t18Fpu2"
      },
      "outputs": [],
      "source": [
        "# Importing Data from google drive\n",
        "dat = pd.read_csv(\"/content/drive/MyDrive/MAF data/Features_seven_signals.csv.zip\")      #Read features + RET\n",
        "\n",
        "# Date-time Manipulations\n",
        "dat[\"date\"] = pd.to_datetime(dat[\"date\"])                                       # \"date\" as a DateTime object\n",
        "dat[\"yr\"] = dat[\"date\"].dt.year                                                 # Extracting year\n",
        "dat[\"month\"] = dat[\"date\"].dt.month                                             # Extracting month\n",
        "dat.sort_values(by = 'date', inplace = True)                                    # Sorting dataframe by date\n",
        "dat[\"month_num\"] = (dat['date']).rank(method = \"dense\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1EQ1jYkJJ3X"
      },
      "outputs": [],
      "source": [
        "\n",
        "dat = dat[dat.yr >= 1990].copy()                                                       #limited availablity of 'oancf' pre-1990\n",
        "#Target is 'adj_return' = 'RET' - 'mean_ret' (average returns for all stocks that month) (why  adj_return and not RET?)\n",
        "\n",
        "# Computing monthly mean returns and storing in columns 'mean_ret'\n",
        "dat['mean_ret'] = dat.groupby('date')['RET'].transform('mean')  # Compute mean returns per date\n",
        "dat['adj_ret'] = dat['RET'] - dat['mean_ret']                                   # Adjusted Returns - subtract the mean so that the target is return minus average returns for all stocks.\n",
        "\n",
        "# Printing Output\n",
        "print(\"***********************************************************\")\n",
        "print(\"Pre-processed Dataframe containing all signals\")\n",
        "print(\"***********************************************************\")\n",
        "dat"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(dat.PERMNO.unique())"
      ],
      "metadata": {
        "id": "9kqkU1ay5XSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dat.columns"
      ],
      "metadata": {
        "id": "LpYMCGm0dzY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AH-TV5oHDybz"
      },
      "outputs": [],
      "source": [
        "## Defining Random Forest Regressor function with output features. The next block of codes call this function\n",
        "# see https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html for details\n",
        "\n",
        "def random_forest_rolling(train_X, train_y, test_X, test_y) :\n",
        "\n",
        "  # Running Random forest model\n",
        "  regressor = RandomForestRegressor(n_estimators=trials, max_features= num_features, max_depth= max_tree_depth, random_state = 0).fit(train_X, train_y)    # Random Forest Regressor Model\n",
        "                                                                            # random_state controls both the randomness of bagging and the sampling of the features to consider when looking for the best split\n",
        "                                                                            #  at each node. Set equal to an integer for reproducability\n",
        "\n",
        "  # Storing & returning the predicted returns based on the model\n",
        "  prediction = regressor.predict(test_X)                                                                                                                    # Storing the predicted returns from the random forest model\n",
        "  R2_score = regressor.score(test_X, test_y)                                                                                                                # Storing the R2 Score between predicted & observed values\n",
        "  return prediction, R2_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PiPiygPqN-pI"
      },
      "outputs": [],
      "source": [
        "## Random Forest : Input parameters\n",
        "y_column_name = 'adj_ret'                                                       #target,\n",
        "features = ['marketcap_pct_rank', 'investment_pct_rank', 'accruals_pct_rank', 'b2m_pct_rank', 'ret_2_12_pct_rank',\t'CashFlow2TA_pct_rank', 'new_issue_pct_rank']\n",
        "#features = ['b2m_pct_rank',  'CashFlow2TA_pct_rank']\n",
        "predicted_ret_df = pd.DataFrame()                                                                           # Initializing \"predicted_ret_df\". This dataframe will store all dataframes\n",
        "#____________________________________________________\n",
        "rolling_window = 60                                                                                        # Training data is comprised of all observation within this window\n",
        "#____________________________________________________\n",
        "last_start_month = int(dat[\"month_num\"].max()) - rolling_window                                            # identify the month to end the for loop and get predictions for the month in the sample period\n",
        "start_time = datetime.now()\n",
        "print('start_time  =', start_time)\n",
        "for t in range(0,last_start_month):                                                                       # Iterating over various rolling windows\n",
        "#for t in range(1,2):\n",
        "  print('t =', t, 'time for loop = ',   datetime.now() -  start_time)\n",
        "  # Input Training data & Test Data Parameters\n",
        "  train_month_start = t                                                                                     # Training data starts from this month number\n",
        "  train_month_end = train_month_start + rolling_window                                                      # Training data ends at this month number\n",
        "                                                                                   # Adjusted Return as the target variable\n",
        "  reg_factors = features\n",
        "\n",
        "  # Input Random Forest Parameters parameter\n",
        "#____________________________________________________\n",
        "  trials = 100;                                                                                             # number of trials or number of trees in each forest. Experiment with other values as well\n",
        "  max_tree_depth = 3;                                                                                       # maximum tree depth. Experiment with other values as well\n",
        "#____________________________________________________\n",
        "  num_features = int(np.sqrt(len(features)))                                                                # Randomly selects \"num_features\" in each node when looking for the best split.\n",
        "                                                                                                            # Therefore, num_features <= len(reg_factors). it is recommended that num_features = sqrt(len(reg_factors))\n",
        "                                                                                                            # With 7 features,  int(np.sqrt(len(reg_factors))) =2. Experiment with other values of num_features, eg. 3\n",
        "\n",
        "  # Extracting Training and Test Data\n",
        "  train_dat = dat[ (dat['month_num'] <= (train_month_end)) & (dat['month_num'] >= (train_month_start)) ]    # Extracting Training Data from \"train_month_start\" till \"train_month_end\"\n",
        "  test_dat = dat[ (dat['month_num'] == train_month_end + 1) ]                                               # Extracting Test Data as data on month \"train_month_end + 1\"\n",
        "  train_X = train_dat[features]                                                                             # Dropping non-signal columns from training data\n",
        "  test_X = test_dat[features]                                                                               # Dropping non-signal columns from test data\n",
        "  train_y = train_dat[y_column_name]                                                                        # Extracting Y values (adjusted returns) in training data\n",
        "  test_y = test_dat[y_column_name]                                                                          # Extracting Y values (adjusted returns) in test data\n",
        "  output_df = random_forest_rolling(train_X, train_y, test_X, test_y)                                       # Calling Random Forest Function, storing predicted_returns and plotting the output (you can change figure size in random_forest function : plt.figure )\n",
        "\n",
        "  ## Predicticted Returns Calculation\n",
        "  test_dat = pd.DataFrame()                                                                                 # Dataframe Initialization\n",
        "  test_dat = dat[(dat['month_num'] == train_month_end + 1)].copy()                                          # Extracts \"Test Data\" or \"t + 1\" month data, where training ends at month \"t\"\n",
        "  test_dat.loc[:,\"predicted_adj_ret\"] = output_df[0]                                                        # Assigning \"predicted returns\" to Test Data\n",
        "  test_dat.rename(columns = {\"adj_ret\" : \"actual_adj_ret\"},inplace = True)\n",
        "  test_dat = test_dat[[\"PERMNO\",\"yr\",\"month\",\"predicted_adj_ret\", \"actual_adj_ret\", \"RET\"]]                 # Keeping only relevant colums\n",
        "  predicted_ret_df = pd.concat([predicted_ret_df, test_dat], axis =0)                                       # Consolding Predicted Returns in \"predicted_ret_df\"\n",
        " #______________________________________________________________________________________________________________________\n",
        "  #This block saves the output in 50 month chunks. Use this option if a full run takes too long and gets interrupted\n",
        "  if t % 50 == 0:\n",
        "  #   Create a new DataFrame for the current chunk\n",
        "   chunk_df = predicted_ret_df[t-50:t].copy()\n",
        "    # Save the chunk to a CSV file\n",
        "   chunk_df.to_csv(f'/content/drive/MyDrive/MAF data/rolling_rf_pred_returns_{t}.csv', index=False)\n",
        "#______________________________________________________________________________________________________________________\n",
        "predicted_ret_df.to_csv(f\"/content/drive/MyDrive/MAF data/rolling_rf_pred_returns_{trials}__{rolling_window}_{max_tree_depth}.csv\")             # Output saved to \"rolling_rf_pred_returns.csv\" file\n",
        "\n",
        "print('over')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_ret_df"
      ],
      "metadata": {
        "id": "Z9v1_QvIIQoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rolling_window = 60\n",
        "trials = 100                                                                                             # number of trials or number of trees in each forest. Experiment with other values as well\n",
        "max_tree_depth = 3\n",
        "predicted_ret_df = pd.read_csv(f\"/content/drive/MyDrive/MAF data/rolling_rf_pred_returns_{trials}__{rolling_window}_{max_tree_depth}.csv\")             # read output previously saved to \"rolling_rf_pred_returns.csv\" file\n"
      ],
      "metadata": {
        "id": "9yo7o1O8dFQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OliTUZgSDxsB"
      },
      "outputs": [],
      "source": [
        "# Decile ranks\n",
        "# At times there  are multiple stocks with the same expected returns. In this case, the number of stocks would vary across decile portfolio.\n",
        "# Step 1 gives a higher rank_order to the first stock when there are multiple stocks with the same expected returns.\n",
        "# Step 1: Rank the data within each year and month group\n",
        "predicted_ret_df['rank_order'] = predicted_ret_df.groupby(['yr', 'month'])['predicted_adj_ret'] \\\n",
        "                                           .rank(method='first')\n",
        "# Step 2: Apply qcut to the ranks to create equal-sized bins\n",
        "predicted_ret_df['rank'] = predicted_ret_df.groupby(['yr', 'month'])['rank_order'] \\\n",
        "                                             .transform(lambda x: pd.qcut(x, 10, labels=False))\n",
        "predicted_ret_df.reset_index(inplace =True,drop = True)                                                                                                                            # Reseting Index\n",
        "\n",
        "## Print Output : Predicted_Ret_Df\n",
        "print(\"****************************************************************************\")\n",
        "print(\"DataFrame with Adjusted Predicted Returns, Deciles(rank) \")\n",
        "print(\"****************************************************************************\")\n",
        "predicted_ret_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKgQQTJ7enVb"
      },
      "outputs": [],
      "source": [
        "# Monthly Mean Portfolio Returns\n",
        "meanret = predicted_ret_df.groupby(['yr','month', 'rank'])['RET'].mean().to_frame()      # Calculating average return for each decile\n",
        "meanret = meanret.unstack(level = -1).copy()                                             # Unstacking the grouped dataframe\n",
        "meanret[('RET', 'diff')] = meanret[('RET', 9)] -  meanret[('RET', 0)]                    # Calculating the long short returns of the portfolio by substracting \"rank 0\" avg. return from \"rank 9\" avg. return\n",
        "\n",
        "nmon = len(meanret)                                                                      # nmon in number of months\n",
        "meanret = meanret.stack(level = -1,future_stack= True).copy()                            # Stacking the dataframe to year-month index level\n",
        "\n",
        "# Overall Portfolio Returns Statistics\n",
        "global_mean = meanret.groupby('rank')['RET'].agg([\"mean\", \"std\"])                      # mean and standard deviation of regression coefficients\n",
        "global_mean['t-stat'] =np.sqrt(nmon - 1) *  global_mean['mean']/global_mean['std']       # t-statistics calculation\n",
        "global_mean"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_ret_df.to_csv(f\"/content/drive/MyDrive/MAF data/dummy.csv.zip\", compression='zip')"
      ],
      "metadata": {
        "id": "kK4qD4A_gAjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meanret"
      ],
      "metadata": {
        "id": "kgeskdk-fLV1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}