{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iekbB6m8QlO"
      },
      "source": [
        "**Quant Model: Multiple Signals**\n",
        "\n",
        "Decile Formation based on combining b2m and CashFlow2TA signals, and Long Short Portfolio Returns\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "copIE672OAWY"
      },
      "source": [
        "**Data Description and code sequence**\n",
        "\n",
        "Important Dataframes\n",
        "\n",
        "1.  \"Returns\" dataframe : It contains monthly returns(RET), shares  outstanding (SHROUT) values, Price (PRC), Primary Exchange Code (PRIMEXCH) and  Unique Identifiers (PERMNO). The data are downloaded from  CRSP.\n",
        "\n",
        "Key Input data:\n",
        "date:    yyyymmdd format\n",
        "RET:     return for the month ending yyyymmdd\n",
        "EXCHCD:  Exchange where listed\n",
        "PRC:   Price as of month-end\n",
        "SHROUT:  Shares outstanding as of month ending yyyymmdd\n",
        "\n",
        "\n",
        "2.   \"Cstat_data\" dataframe : Compustat data used to construct features\n",
        "\n",
        "  LPERMNO: CRSP identifier - relable to PERMNO to merge\n",
        "  ceq: book value of common equity\n",
        "  oancf: Cash flow from (oancf))/ total assets (at)\n",
        "\n",
        "  #normalized by total assetes so that CashFlows are comparable across stocks of different sizes\n",
        "\n",
        "\n",
        "\n",
        "3. merged_data : Dataframe obtained from Merging \"Returns\" & \"Cstat_data\" dataframe on \"PERMNO\" & \"date\". Merge with \"pd.merge_asof\" command to match CRSP 'date' with the lastest COMPUSTAT 'datadate' with 1 year tolerance for merging. Book to Market Ratio (b2m) is calculated using ceq and marketcap values.\n",
        "\n",
        "4. Signals:\n",
        "\n",
        "\n",
        "\n",
        "*  Sort based on one signal at a time\n",
        "\n",
        "\n",
        "  a. b2m: Book-to-market\n",
        "\n",
        "  b. CashFlow2AT: oancf/Assets (AT)\n",
        "\n",
        "* combine signals and then sort based on the combined signal\n",
        "  \n",
        "  c. Combined signal = pct score of b2m +  pct score of CashFlow2TA_rank\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ETFMCJHMaq6h"
      },
      "outputs": [],
      "source": [
        "# Connecting the Python Code with the google drive to access the datasets\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2a7sxymZTL7X"
      },
      "outputs": [],
      "source": [
        "# Importing Necessary Python Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "from datetime import timedelta\n",
        "from pandas import DateOffset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "746SXhvElbaD"
      },
      "outputs": [],
      "source": [
        "#CRSP Data\n",
        "\n",
        "# Importing CRSP price and returns datasets\n",
        "Returns = pd.read_csv(\"/content/drive/MyDrive/MAF data/MonthlyRet_198001_202312csv.zip\") #Importing Cleaned CRSP data\n",
        "\n",
        "# Handling Missing values\n",
        "Returns.PRC = abs(Returns.PRC)                                         # Converting Price Values to absolute numbers (CRSP sets PRC with a \"-\" symbol if it is comuted as bid-ask average when there is no actual trade)\n",
        "\n",
        "# Market Cap Calculation\n",
        "Returns['marketcap'] = Returns.SHROUT * Returns.PRC                    #  Market Capitalization as of month end\n",
        "Returns['marketcap'] = Returns.groupby('PERMNO')['marketcap'].shift()  # Lagged Market Capitalization = market cap as of the end of the previous month\n",
        "Returns['marketcap'] = np.where(Returns['marketcap'] < 10000, np.nan, Returns['marketcap']) # exclude marketcap < $10m\n",
        "\n",
        "# Exchange Code Filters\n",
        "exch_nyse_amex_Nasdaq = ['N', 'Q', 'A']\n",
        "Returns = Returns[Returns.PRIMEXCH.isin(exch_nyse_amex_Nasdaq)].copy() #keeping only NYSE (N), AMEX(A) and Nasdaq (Q) stocks, ie. stocks listed on  US exchanges)\n",
        "\n",
        "#Keep only ordinary common shares\n",
        "ord_common_shares = [10, 11, 12]\n",
        "Returns = Returns[Returns.SHRCD.isin(ord_common_shares)].copy()             #keeping only ordinary common shares - excludes unit trusts, ADRS, REITS, closed-end funds\n",
        "\n",
        "# Minor Pre-processing\n",
        "Returns.reset_index(inplace = True, drop = True)                                                # Reset Index\n",
        "\n",
        "Returns = Returns[[\"PERMNO\",\"PRIMEXCH\",\"date\",\"RET\",\"PRC\",\"SHROUT\",\"marketcap\"]].copy() # Reordering the columns for clarity\n",
        "Returns.RET = pd.to_numeric(Returns.RET, errors = 'coerce')                      #RET denoted missing value with alphanumeric values. convert it to Numeric with the 'coerce' option to set nonnumeric value to nan.\n",
        "\n",
        "Returns.dropna(inplace = True)\n",
        "#CRSP Data , prepare Date-time for merging with Compustat data\n",
        "\n",
        "Returns[\"date\"] = pd.to_datetime(Returns[\"date\"])                       # Convert  \"date\" to a DateTime object\n",
        "Returns[\"year\"] = Returns[\"date\"].dt.year                              # Extracting year\n",
        "Returns[\"month\"] = Returns[\"date\"].dt.month                            # Extracting month\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAC2AmkIWHks"
      },
      "outputs": [],
      "source": [
        "#Compustat Data\n",
        "\n",
        "# Importing Compustat Data\n",
        "Cstat_data = pd.read_csv('/content/drive/MyDrive/MAF data/Cstat_20250108.zip')     # Importing monthly Compustat data\n",
        "\n",
        "Cstat_data.rename(columns = {'LPERMNO' : 'PERMNO'}, inplace = True) # Renaming \"LPERMNO\" for merging Cstat data with CRSP data\n",
        "Cstat_data['at'] = Cstat_data['at'].apply(lambda x: 0.5 if x < 0.5 else x) #setting at to a min value of 0.5 because 'at' can be < 0 some stocks\n",
        "Cstat_data['CashFlow2TA'] = Cstat_data['oancf']/ Cstat_data['at']               # Cash flow from operations (oancf)]/Assets (AT)\n",
        "\n",
        "#Date time for Compustat Data - When will the data be available to the market?\n",
        "\n",
        "# Datetime Manipulations\n",
        "Cstat_data[\"date\"] = pd.to_datetime(Cstat_data[\"datadate\"])        # Convert to  DateTime object for datetime manipulations\n",
        "Cstat_data['date'] = Cstat_data['date'].apply(lambda x: x + DateOffset(months=+5))  # Adding five months (using DataOffset library) assuming it takes at most 4 months for the data to reach the market\n",
        "\n",
        "Cstat_data = Cstat_data[['date', 'PERMNO', 'datadate', 'ceq', 'CashFlow2TA']].copy()  #retain only data needed further\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Cstat_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XEKiuT0rcUw"
      },
      "outputs": [],
      "source": [
        "Cstat_data['CashFlow2TA'].min(), Cstat_data['CashFlow2TA'].max()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgASYjxqUkzR"
      },
      "source": [
        "Merge CRSP and Compusta data by PERMNO.\n",
        "Ensure no look-ahead bias:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1atD3nIVS0mw"
      },
      "outputs": [],
      "source": [
        "# Merged Data\n",
        "\n",
        "Returns.sort_values(by = 'date', inplace = True)                       # Sort CRSP data by date to use merge_asof\n",
        "Cstat_data.sort_values(by = 'date', inplace = True)                 # Sort Cstat data by date to use merge_asof\n",
        "\n",
        "\n",
        "merged_data = pd.merge_asof(Returns, Cstat_data, by = 'PERMNO', left_on = 'date', right_on= 'date', tolerance=dt.timedelta(days = 365)) # Merging \"Returns\" & \"Cstat\" dataframe on \"PERMNO\" & \"date\" with a 1-year tolerance for date\n",
        "\n",
        "# Calculating Book to Market Ratio\n",
        "merged_data['b2m'] = merged_data.ceq / merged_data.marketcap      # Book to Market Ratio\n",
        "\n",
        "\n",
        "merged_data.dropna(subset=['RET', 'CashFlow2TA', 'b2m'], how = 'any', inplace = True) #drop only if the  data items we need later are missing\n",
        "merged_data.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INYjpkrCYlIK"
      },
      "outputs": [],
      "source": [
        "# Compute decile portfolio returns\n",
        "merged_data = merged_data[merged_data.year >= 2000].copy()        # Including data with year greater than equal to 2000\n",
        "merged_data['b2m_rank'] = merged_data.groupby(['year','month'])['b2m'].transform(lambda x: pd.qcut(x, 10, duplicates='drop',labels=False)) #  Ranks based on Book to Market Value each month\n",
        "merged_data['CashFlow2TA_rank'] = merged_data.groupby(['year','month'])['CashFlow2TA'].transform(lambda x: pd.qcut(x, 10, duplicates='drop',labels=False)) # Ranks based on CashFlow2TA each month\n",
        "\n",
        "merged_data.reset_index(inplace = True, drop = True)              # Reset Index\n",
        "\n",
        "merged_data.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OkObMrodn882"
      },
      "outputs": [],
      "source": [
        "# Monthly Mean Portfolio Returns for b2m_rank\n",
        "meanret = merged_data.groupby(['year','month', 'b2m_rank'])['RET'].mean().to_frame()   # Calculating average return for each decile (according to b2m ratio) for each month\n",
        "meanret.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the difference between extreme portfolio returns and the Global mean\n",
        "meanret = meanret.unstack(level = -1).copy()                                       # Unstacking the grouped dataframe\n",
        "meanret[('RET', 'diff')] = meanret[('RET', 9)] -  meanret[('RET', 0)]              # Calculating the long short returns of the portfolio by substracting \"rank 0\" avg. return from \"rank 9\" avg. return\n",
        "\n",
        "nmon = len(meanret)                                                                # nmon in number of months\n",
        "meanret = meanret.stack(level = -1, future_stack=True).copy()                                         # Stacking the dataframe to year-month index level\n",
        "meanret"
      ],
      "metadata": {
        "id": "g_wzV7gj_oPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Portfolio  Statistics\n",
        "# Third level index (b2m_rank) and make it a column\n",
        "meanret = meanret.reset_index(level=2)\n",
        "# Calculate mean and standard deviation for each b2m_rank\n",
        "global_mean_b2m = meanret.groupby('b2m_rank')['RET'].agg(['mean', 'std'])\n",
        "global_mean_b2m['t-stat'] = np.sqrt(nmon - 1) * global_mean_b2m['mean'] / global_mean_b2m['std']  # t-statistics calculation\n",
        "\n",
        "global_mean_b2m"
      ],
      "metadata": {
        "id": "4WBcjW13Cseg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GzKDSVZIiBv-"
      },
      "outputs": [],
      "source": [
        "# Monthly Mean Portfolio Returns for CashFlow2TA_rank\n",
        "meanret = merged_data.groupby(['year','month', 'CashFlow2TA_rank'])['RET'].mean().to_frame()   # Calculating average monthly return for each decile (formed based on CashFlow2TA_rank)\n",
        "meanret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVhjw8iJizL5"
      },
      "outputs": [],
      "source": [
        "# Compute the difference between extreme portfolio returns and the Global mean for CashFlow2TA_rank\n",
        "meanret = meanret.unstack(level = -1).copy()                                       # Unstacking the grouped dataframe\n",
        "meanret[('RET', 'diff')] = meanret[('RET', 9)] -  meanret[('RET', 0)]              # Calculating the long short returns of the portfolio by substracting \"rank 0\" avg. return from \"rank 9\" avg. return\n",
        "\n",
        "nmon = len(meanret)                                                                # nmon in number of months\n",
        "meanret = meanret.stack(level = -1, future_stack=True).copy()                                         # Stacking the dataframe to year-month index level\n",
        "\n",
        "# Overall Portfolio Returns Statistics\n",
        "global_mean_CashFlow2TA = meanret.groupby('CashFlow2TA_rank')['RET'].agg(['mean', 'std'])                # mean and standard deviation of regression coefficients\n",
        "global_mean_CashFlow2TA['t-stat'] =np.sqrt(nmon - 1) *  global_mean_CashFlow2TA['mean']/global_mean_CashFlow2TA['std'] # t-statistics calculation\n",
        "global_mean_CashFlow2TA\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qz21708otyb7"
      },
      "source": [
        "What does the evidence that bigger Cash flow stocks earn bigger returns suggest?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cf2ta = global_mean_CashFlow2TA['mean'].to_frame().copy()\n",
        "b2m = global_mean_b2m['mean'].to_frame().copy()\n",
        "cf2ta.reset_index(inplace=True)\n",
        "b2m.reset_index(inplace=True)\n",
        "b2m.rename(columns = {'mean' : 'b2m_mean', 'b2m_rank' : 'rank'}, inplace = True)\n",
        "cf2ta.rename(columns = {'mean' : 'cf2ta_mean', 'CashFlow2TA_rank' : 'rank'}, inplace = True)\n",
        "print(cf2ta)"
      ],
      "metadata": {
        "id": "rpNy4vkcHoWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge data\n",
        "df = pd.merge(b2m, cf2ta, on = 'rank')\n",
        "# Filter out rows with 'diff' before conversion\n",
        "df = df[df['rank'] != 'diff']  # Filter out 'diff'\n",
        "df['rank']=df['rank'].astype(int)\n",
        "df"
      ],
      "metadata": {
        "id": "HMYmxTJ90cGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# Merge data\n",
        "df = pd.merge(b2m, cf2ta, on = 'rank')\n",
        "# Filter out rows with 'diff' before conversion\n",
        "df = df[df['rank'] != 'diff']  # Filter out 'diff'\n",
        "df['rank']=df['rank'].astype(int)\n",
        "\n",
        "# Create mesh grid\n",
        "X, Y = np.meshgrid(df['rank'], df['rank'])\n",
        "X = X.flatten()  # Convert to 1D array\n",
        "Y = Y.flatten()\n",
        "Z = np.zeros_like(X)  # Z starts at zero\n",
        "\n",
        "# Heights of bars (b2m_mean from both datasets)\n",
        "bar_heights = np.array([b2m_val + cf2ta_val for b2m_val in df['b2m_mean'] for cf2ta_val in df['cf2ta_mean']])\n",
        "\n",
        "# Bar sizes\n",
        "width = depth = 0.4\n",
        "\n",
        "# Create 3D figure\n",
        "fig = plt.figure(figsize=(12, 8))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# Plot 100 bars\n",
        "ax.bar3d(X, Y, Z, width, depth, bar_heights, shade=True)\n",
        "\n",
        "# Labels and title\n",
        "ax.set_xlabel('b2m Rank')\n",
        "ax.set_ylabel('cf2ta Rank')\n",
        "ax.set_zlabel(' Return')\n",
        "plt.title('B2M Mean vs. CF2TA Mean by Rank')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "T5lG1NC5VjRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0f8EfbwSj9Nc"
      },
      "outputs": [],
      "source": [
        "#combine scores - ensure that bigger score implies better signal\n",
        "merged_data['b2m_pct_rank']= merged_data.groupby(['year','month'])['b2m'].rank(pct = True)\n",
        "merged_data['CashFlow2TA_rank']= merged_data.groupby(['year','month'])['CashFlow2TA'].rank(pct = True)\n",
        "merged_data['combined_pct_rank'] = merged_data['b2m_pct_rank'] + merged_data['CashFlow2TA_rank']\n",
        "merged_data.dropna(subset = ['RET', 'combined_pct_rank'], how = 'any', inplace = True)   #Drop only observations where relevant variables are nan\n",
        "merged_data = merged_data.loc[merged_data.year >= 2000].copy()\n",
        "merged_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-JEdNrxkz_U"
      },
      "outputs": [],
      "source": [
        "n_cut = 10\n",
        "merged_data['combined_rank'] = merged_data.groupby(['year','month'])['combined_pct_rank'].transform(lambda x: pd.qcut(x, n_cut, duplicates='drop',labels=False)) # Calculating Ranks based on combined_pct_rank\n",
        "meanret = merged_data.groupby(['year','month', 'combined_rank'])['RET'].mean().to_frame()   # Calculate average monthly return for each combined_rank decile\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XOd_iRHKtFaR"
      },
      "outputs": [],
      "source": [
        "# Compute the difference between extreme portfolio returns and the Global mean for combined_pct_rank\n",
        "meanret = meanret.unstack(level = -1).copy()                                       # Unstacking the grouped dataframe\n",
        "meanret[('RET', 'diff')] = meanret[('RET', n_cut - 1)] -  meanret[('RET', 0)]              # Calculating the long short returns of the portfolio by substracting \"rank 0\" avg. return from \"rank 9\" avg. return\n",
        "\n",
        "nmon = len(meanret)                                                                # nmon in number of months\n",
        "meanret = meanret.stack(level = -1, future_stack=True).copy()                                         # Stacking the dataframe to year-month index level\n",
        "\n",
        "# Overall Portfolio Returns Statistics\n",
        "global_mean_combined = meanret.groupby('combined_rank')['RET'].agg(['mean', 'std'])                # mean and standard deviation of regression coefficients\n",
        "global_mean_combined['t-stat'] =np.sqrt(nmon - 1) *  global_mean_combined['mean']/global_mean_combined['std'] # t-statistics calculation\n",
        "global_mean_combined\n",
        "\n"
      ]
    },
    {
      "source": [
        "#Plot average returns for each decile\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Plot bar chart using DataFrame\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "# Filter out the 'diff' row before plotting\n",
        "global_mean_b2m_filtered = global_mean_b2m[global_mean_b2m.index != 'diff']\n",
        "\n",
        "# Accessing the index values instead of a column\n",
        "plt.bar(global_mean_b2m_filtered.index, global_mean_b2m_filtered['mean'], color='skyblue', edgecolor='black')\n",
        "\n",
        "\n",
        "# Labels and title\n",
        "plt.xlabel(\"Combined Rank Deciles\")\n",
        "plt.ylabel(\"Mean Return\")\n",
        "plt.title(\"Mean Return by Combined Rank Decile\")\n",
        "# Ensuring integer tick labels:\n",
        "# Convert index to integers or strings before passing to plt.xticks\n",
        "plt.xticks(global_mean_b2m_filtered.index.astype(int)) #or plt.xticks(global_mean_b2m_filtered.index.astype(str))\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "# Show plot\n",
        "plt.show()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "6xoL0fb03fWY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}