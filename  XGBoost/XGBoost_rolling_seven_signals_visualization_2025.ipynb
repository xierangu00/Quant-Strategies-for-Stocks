{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5VtFEfZzoVf"
      },
      "source": [
        "**Lecture  : XGBoosting**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ETFMCJHMaq6h"
      },
      "outputs": [],
      "source": [
        "# Connecting the Python Code with the google drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0n_BSmB9o1Za"
      },
      "outputs": [],
      "source": [
        "!pip install xgbtune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6UrtAekr6vaE"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import sys\n",
        "import os\n",
        "import platform\n",
        "import random\n",
        "from math import sqrt, floor, ceil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "from multiprocessing import Process\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import xgboost as xgb\n",
        "from sklearn.tree import plot_tree\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from xgbtune import tune_xgb_model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Description**\n",
        "\n",
        "Input: /content/drive/MyDrive/MAF data/Features_seven_signals.csv.zip\n",
        "Created by: Lec5_Create Standardized Features.ipynb\n",
        "\n",
        " **Satandardized Features**\n",
        "\n",
        "* marketcap: market cap\n",
        "\n",
        "* investment: 12-month increase in total assets\n",
        "\n",
        "* accruals: ib - oancf\n",
        "\n",
        "* b2m: ceq/marketcap\n",
        "\n",
        "* ret_2_12: momentum (stock returns from month t-12 to t-2\n",
        "\n",
        "* CashFlow2AT: oancf/Assets (AT)\n",
        "*new_issue: Stocks issued over the previous 12 months\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "copIE672OAWY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dat = pd.read_csv(\"/content/drive/MyDrive/MAF data/Features_seven_signals.csv.zip\")\n",
        "dat\n"
      ],
      "metadata": {
        "id": "y8pBebZUb0uq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dat[\"PERMNO\"].nunique()"
      ],
      "metadata": {
        "id": "nOpf2WgOKdzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1EQ1jYkJJ3X"
      },
      "outputs": [],
      "source": [
        "# Data Pre-processing\n",
        "\n",
        "# Date-time Manipulations\n",
        "dat[\"date\"] = pd.to_datetime(dat[\"date\"])                                       # \"date\" as a DateTime object# Informing python that \"date\" is a DateTime object for subsequent datetime manipulations like adding or subtracting months\n",
        "dat[\"yr\"] = dat[\"date\"].dt.year                                                 # Extracting year\n",
        "dat[\"month\"] = dat[\"date\"].dt.month                                             # Extracting month\n",
        "dat.sort_values(by = 'date', inplace = True)                                    # Sorting dataframe by date\n",
        "dat[\"month_num\"] = (dat['date']).rank(method = \"dense\")                         # Assigning a rank for each month sequentially\n",
        "\n",
        "\n",
        "# Calculating Mean & Adjusted Returns\n",
        "grouped = pd.DataFrame();                                                       # Initializing DataFrame\n",
        "grouped[\"mean\"] = dat.groupby('date').apply(lambda x : x[\"RET\"].mean())       # Computing monthly mean returns\n",
        "dat['mean_ret'] = dat['date'].map(grouped[\"mean\"])                            # Assigning mean returns to \"dat[\"mean_ret\"]\" column\n",
        "dat['adj_ret'] = dat['RET'] - dat['mean_ret']                                   # Adjusted Returns - subtract the mean so that the target is return minus average returns for all stocks.\n",
        "\n",
        "# Reordering Columns\n",
        "dat = dat[['date','PERMNO', 'marketcap_pct_rank','new_issue_pct_rank',\n",
        "           'investment_pct_rank', 'accruals_pct_rank', 'b2m_pct_rank',\n",
        "           'ret_2_12_pct_rank','CashFlow2TA_pct_rank', 'RET', 'mean_ret', 'adj_ret', 'yr',\n",
        "           'month', 'month_num']]\n",
        "\n",
        "# Printing Output\n",
        "print(\"***********************************************************\")\n",
        "print(\"Pre-processed Dataframe containing all signals\")\n",
        "print(\"***********************************************************\")\n",
        "dat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHpkCfe7bYvi"
      },
      "outputs": [],
      "source": [
        "# Minor Pre-processing to extract available factors\n",
        "y_column_name = 'adj_ret'                                                                                               # Target variable is adjusted returns\n",
        "row_key_column_names = ['yyyymm', 'PERMNO', 'month', 'yr', 'month_num', 'RET', 'mean_ret','date']                       # Columns that are not signals ( either identifiers or target variables )\n",
        "feature_column_names = [ x for x in dat.columns.values if (x not in row_key_column_names) & (x != y_column_name) ]      # Remaining columns are the varaibles that can potentailly be used as signals\n",
        "print(\"************************************************************************************************************\")\n",
        "print(\"list of Input signals/features\")\n",
        "print(feature_column_names)\n",
        "print(\"************************************************************************************************************\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "See [documentation](https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fxgboost.readthedocs.io%2Fen%2Fstable%2Fparameter.html&data=05%7C02%7Cjegadeesh%40emory.edu%7C23f5c662701c490daf9708dd4f674f9f%7Ce004fb9cb0a4424fbcd0322606d5df38%7C0%7C0%7C638754027358065687%7CUnknown%7CTWFpbGZsb3d8eyJFbXB0eU1hcGkiOnRydWUsIlYiOiIwLjAuMDAwMCIsIlAiOiJXaW4zMiIsIkFOIjoiTWFpbCIsIldUIjoyfQ%3D%3D%7C0%7C%7C%7C&sdata=E%2Bi9ZLJ3gDQ1ImVumHHm1pknFFAksYjBE8orFkqkeYs%3D&reserved=0) here for  additional details"
      ],
      "metadata": {
        "id": "RRmVKacd7N0Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjcU7ooRwElg"
      },
      "outputs": [],
      "source": [
        "## Defining XGBoost Regressor function with output features. The next block of codes call this function\n",
        "\n",
        "def xgboost_rolling(train_X, train_y, test_X, test_y) :\n",
        "  \"\"\"\n",
        "  params = {'eval_metric': 'rmse'}\n",
        "  params, round_count = tune_xgb_model(params, train_X, train_y)\n",
        "  print(params)\n",
        "  print(round_count)\n",
        "  \"\"\"\n",
        "  params = {'eval_metric': 'rmse', 'max_depth': 4, 'min_child_weight': 1, 'gamma': 0.2, 'subsample': 1.0, 'colsample_bytree': 0.8, 'alpha': 0, 'lambda': 1, 'learning_rate' : 0.3, 'seed': 0}\n",
        "\n",
        "  regressor_main =xgb.XGBRegressor(**params)\n",
        "\n",
        "  regressor_main.fit(train_X, train_y)\n",
        "  prediction = regressor_main.predict(test_X)     # Storing the R2 Score between predicted & observed values\n",
        "  R2_score = regressor_main.score(test_X, test_y)\n",
        "  #print(prediction, R2_score)\n",
        "  return prediction, R2_score, regressor_main\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PiPiygPqN-pI"
      },
      "outputs": [],
      "source": [
        "## XGBoost\n",
        "\n",
        "predicted_ret_df = pd.DataFrame()                                                                           # Initializing \"predicted_ret_df\". This dataframe will store all dataframes\n",
        "rolling_window = 60                                                                                         # Training data is comprised of all observation within this window\n",
        "start_month_limit = int(dat[\"month_num\"].max()) - rolling_window                                            # last \"rolling window starting point\" that is possible\n",
        "\n",
        "for t in range(1,start_month_limit):                                                                        # Iterating over various rolling windows\n",
        "  if t % 10 == 0:                                                                                           #print t every 10 months\n",
        "    print(t)\n",
        "  # Input Training data & Test Data Parameters\n",
        "  train_month_start = t                                                                                     # Training data start from this month number, input any number from 1 till 380 (based on dat[\"month_num\"])\n",
        "  train_month_end = train_month_start + rolling_window                                                      # Training data ends at this month number\n",
        "  y_column_name = 'adj_ret'                                                                                 # Adjusted Return as the target variable\n",
        "  reg_factors = feature_column_names\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # Extracting Training and Test Data\n",
        "  train_dat = dat[ (dat['month_num'] <= (train_month_end)) & (dat['month_num'] >= (train_month_start)) ]    # Extracting Training Data from \"train_month_start\" till \"train_month_end\"\n",
        "  test_dat = dat[ (dat['month_num'] == train_month_end + 1) ]                                               # Extracting Test Data as data on month \"train_month_end + 1\"\n",
        "  train_X = train_dat[reg_factors]                                                                          # Dropping non-signal columns from training data\n",
        "  test_X = test_dat[reg_factors]                                                                            # Dropping non-signal columns from test data\n",
        "  train_y = train_dat[y_column_name]                                                                        # Extracting Y values (adjusted returns) in training data\n",
        "  test_y = test_dat[y_column_name]                                                                          # Extracting Y values (adjusted returns) in test data\n",
        "  output_df = xgboost_rolling(train_X, train_y, test_X, test_y)                                             # Calling Random Forest Function, storing predicted_returns and plotting the output (you can change figure size in random_forest function : plt.figure )\n",
        "\n",
        "  ## Predicticted Returns Calculation\n",
        "  test_dat = pd.DataFrame()                                                                                 # Dataframe Initialization\n",
        "  test_dat = dat[(dat['month_num'] == train_month_end + 1)].copy()                                          # Extracts \"Test Data\" or \"t + 1\" month data, where training ends at month \"t\"\n",
        "  test_dat.loc[:,\"predicted_adj_ret\"] = output_df[0]                                                        # Assigning \"predicted returns\" to Test Data\n",
        "  test_dat.rename(columns = {\"adj_ret\" : \"actual_adj_ret\"},inplace = True)\n",
        "  test_dat = test_dat[[\"PERMNO\",\"yr\",\"month\",\"predicted_adj_ret\", \"actual_adj_ret\", \"RET\"]]                 # Keeping only relevant colums\n",
        "  predicted_ret_df = pd.concat([predicted_ret_df, test_dat], axis =0)                                       # Consolding Predicted Returns in \"predicted_ret_df\"\n",
        "\n",
        "predicted_ret_df.to_csv(\"/content/drive/MyDrive/MAF data/rolling_xgb_pred_returns.csv\")             # Output saved to \"rolling_rf_pred_returns.csv\" file\n",
        "\n",
        "print(\"****************************************************************************\")\n",
        "print(\"Dataframe with predicted returns\")\n",
        "print(\"****************************************************************************\")\n",
        "predicted_ret_df\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Plot Feature Importance\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model = output_df[2]\n",
        "\n",
        "# Extract feature importance\n",
        "feature_importance = model.feature_importances_\n",
        "feature_names = train_X.columns\n",
        "\n",
        "# Sort feature importance\n",
        "sorted_indices = feature_importance.argsort()  # Get indices for sorting\n",
        "sorted_feature_importance = feature_importance[sorted_indices]\n",
        "sorted_feature_names = feature_names[sorted_indices]\n",
        "\n",
        "# Plotting feature importance\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(sorted_feature_names, sorted_feature_importance)\n",
        "plt.xlabel('Feature Importance')\n",
        "plt.ylabel('Feature Names')\n",
        "plt.title('XGBoost Model Signal Importance ')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9u7Zpa2HKaur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Extracting Tree Details\n",
        "# Extract tree details as a DataFrame\n",
        "\"\"\"\n",
        "\"Tree\": The index of the tree in the ensemble. XGBoost is an ensemble of multiple trees, so this indicates which tree the node belongs to.\n",
        "\n",
        "\"Node\": The ID of the node within the tree. In the first row, 0 is the root node, and 0-1, 0-2, etc., are child nodes.\n",
        "\n",
        "\"ID\" : Tree Node Unique Id\n",
        "\n",
        "\"Feature\": The feature used for splitting at this node.\n",
        "\n",
        "\"Split\": The threshold value used for the split.\n",
        "\n",
        "\"Yes\": The ID of the child node to go to if the condition (feature ≤ split threshold) is true.\n",
        "\n",
        "\"No\": The ID of the child node to go to if the condition (feature > split threshold) is false.\n",
        "\n",
        "\"Missing\": The ID of the child node to go to if the feature value is missing (NaN).\n",
        "\n",
        "\"Gain\": The improvement in the objective function (e.g., loss reduction) achieved by splitting at this node.For leaves, it represents prediction value in a broader sense.\n",
        "\n",
        "\"Cover\": The number of samples associated with this node.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "tree_df = model.get_booster().trees_to_dataframe()\n",
        "del tree_df[\"Category\"]\n",
        "tree_df[tree_df[\"Tree\"]==0] # we can change the value based on which tree we want to see"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ykYihXuXN2pp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Plotting A Sample XGBoost Tree\n",
        "from xgboost import to_graphviz\n",
        "import graphviz\n",
        "from IPython.display import Image\n",
        "\n",
        "# Generating tree\n",
        "graph = to_graphviz(model, num_trees=0, rankdir='LR') # num_trees is the ith tree that we want to visualize\n",
        "file_path = graph.render('xgboost_tree', format='png')\n",
        "\n",
        "\n",
        "# Plot\n",
        "Image(filename=file_path)"
      ],
      "metadata": {
        "id": "w78ZPP2qMj_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_ret_df = pd.read_csv(\"/content/drive/MyDrive/MAF data/rolling_xgb_pred_returns.csv\")             # read output previously saved to \"rolling_rf_pred_returns.csv\" file\n"
      ],
      "metadata": {
        "id": "9yo7o1O8dFQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3183BakxjiHW"
      },
      "outputs": [],
      "source": [
        "# Decile ranks\n",
        "# At times there  are multiple stocks with the same expected returns. In this case, the number of stocks would vary across decile portfolio.\n",
        "# Step 1 gives a higher rank_order to the first stock when there are multiple stocks with the same expected returns.\n",
        "# Step 1: Rank the data within each year and month group\n",
        "predicted_ret_df['rank_order'] = predicted_ret_df.groupby(['yr', 'month'])['predicted_adj_ret'] \\\n",
        "                                           .rank(method='first')\n",
        "# Step 2: Apply qcut to the ranks to create equal-sized bins\n",
        "predicted_ret_df['rank'] = predicted_ret_df.groupby(['yr', 'month'])['rank_order'] \\\n",
        "                                             .transform(lambda x: pd.qcut(x, 10, labels=False))\n",
        "predicted_ret_df.reset_index(inplace =True,drop = True)                                                                                                                            # Reseting Index\n",
        "\n",
        "## Print Output : Predicted_Ret_Df\n",
        "print(\"****************************************************************************\")\n",
        "print(\"DataFrame with Adjusted Predicted Returns, Deciles(rank) \")\n",
        "print(\"****************************************************************************\")\n",
        "predicted_ret_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OliTUZgSDxsB"
      },
      "outputs": [],
      "source": [
        "# Decile formation & Predicted Returns Calculation\n",
        "predicted_ret_df['rank'] = predicted_ret_df.groupby(['yr','month'])['predicted_adj_ret'].transform(lambda x: pd.qcut(x, 10, duplicates='drop',labels=False))         # Calculating Decile Ranks based on the Predicted Returns\n",
        "predicted_ret_df.reset_index(inplace =True,drop = True)                                                                                                                            # Reseting Index\n",
        "\n",
        "## Print Output : Predicted_Ret_Df\n",
        "print(\"****************************************************************************\")\n",
        "print(\"DataFrame with Adjusted Predicted Returns, Deciles(rank) \")\n",
        "print(\"****************************************************************************\")\n",
        "predicted_ret_df"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nXBESJXvm258"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = predicted_ret_df.groupby(['yr','month']).count()\n",
        "count"
      ],
      "metadata": {
        "id": "7CjQRST0m3OW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nyb9eWr83yxT"
      },
      "outputs": [],
      "source": [
        "# Monthly Mean Portfolio Returns\n",
        "meanret = predicted_ret_df.groupby(['yr','month', 'rank'])['RET'].mean().to_frame()      # Calculating average return for each decile\n",
        "meanret = meanret.unstack(level = -1).copy()                                             # Unstacking the grouped dataframe\n",
        "meanret[('RET', 'diff')] = meanret[('RET', 9)] -  meanret[('RET', 0)]                    # Calculating the long short returns of the portfolio by substracting \"rank 0\" avg. return from \"rank 9\" avg. return\n",
        "\n",
        "nmon = len(meanret)                                                                      # nmon in number of months\n",
        "meanret = meanret.stack(level = -1,future_stack= True).copy()                            # Stacking the dataframe to year-month index level\n",
        "\n",
        "# Overall Portfolio Returns Statistics\n",
        "global_mean = meanret.groupby('rank')['RET'].agg([\"mean\", \"std\"])                      # mean and standard deviation of regression coefficients\n",
        "global_mean['t-stat'] =np.sqrt(nmon - 1) *  global_mean['mean']/global_mean['std']       # t-statistics calculation\n",
        "global_mean"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}